# Sales Insights API - Agente RAG com Gemini

Este projeto foi desenvolvido como parte de um processo seletivo, demonstrando a cria√ß√£o de uma API de an√°lise de vendas que utiliza um agente RAG (Retrieval-Augmented Generation) com o modelo Gemini do Google para responder a perguntas em linguagem natural sobre dados de um banco de dados PostgreSQL.

## üìú Vis√£o Geral

A aplica√ß√£o consiste em uma API RESTful constru√≠da com FastAPI que exp√µe endpoints para obter insights de vendas. O principal diferencial √© o endpoint `/sales-insights`, que permite ao usu√°rio fazer perguntas complexas em portugu√™s (ex: "qual foi o produto mais vendido no √∫ltimo m√™s?"), que s√£o traduzidas para consultas SQL, executadas e respondidas de forma clara e objetiva.

## ‚ú® Features

-   **API RESTful**: Interface clara e documentada para interagir com os dados de vendas.
-   **An√°lise de Vendas**: Endpoint `/top-products` para listar os produtos mais vendidos no √∫ltimo m√™s.
-   **Consultas em Linguagem Natural**: Endpoint `/sales-insights` que utiliza um agente RAG com o LLM Gemini 1.5 Flash para responder perguntas sobre os dados.
-   **Arquitetura Robusta**: Uso de SQLAlchemy para ORM, Pydantic para valida√ß√£o de dados e LangChain para orquestrar a l√≥gica do agente.
-   **Ambiente Containerizado**: Configura√ß√£o completa com Docker e Docker Compose para garantir uma execu√ß√£o simples e consistente em qualquer ambiente.

## üõ†Ô∏è Arquitetura e Tecnologias

O projeto utiliza as seguintes tecnologias:

-   **Backend**: Python 3.9+
-   **Framework da API**: FastAPI
-   **Banco de Dados**: PostgreSQL
-   **ORM**: SQLAlchemy
-   **LLM e RAG**: Google Gemini & LangChain
-   **Containeriza√ß√£o**: Docker & Docker Compose

### Fluxo da Requisi√ß√£o RAG (`/sales-insights`)

1.  **Pergunta do Usu√°rio**: O usu√°rio envia uma pergunta em linguagem natural (ex: "Qual cliente comprou mais?").
2.  **Gera√ß√£o de SQL**: O LangChain, com a ajuda do prompt de engenharia e do modelo Gemini, analisa a pergunta e a estrutura das tabelas do banco de dados para gerar uma consulta SQL correspondente.
3.  **Limpeza da Consulta**: Uma fun√ß√£o intermedi√°ria remove artefatos (como blocos de markdown ` ```sql`) da consulta gerada pelo LLM.
4.  **Execu√ß√£o no BD**: A consulta SQL limpa √© executada no banco de dados PostgreSQL.
5.  **Gera√ß√£o da Resposta**: O resultado da consulta √© enviado de volta ao Gemini, que gera uma resposta final em portugu√™s, de forma clara e n√£o-t√©cnica.
6.  **Resposta da API**: A API retorna a resposta final ao usu√°rio.

## üöÄ Como Rodar o Projeto

A maneira mais simples de rodar este projeto √© utilizando Docker.

### Pr√©-requisitos

-   [Docker](https://www.docker.com/get-started) e [Docker Compose](https://docs.docker.com/compose/install/) instalados.
-   Uma chave de API do **Google Gemini**. Voc√™ pode obter uma gratuitamente no [Google AI Studio](https://aistudio.google.com/app/apikey).

### 1. Clonar o Reposit√≥rio

```bash
git clone <URL_DO_SEU_REPOSITORIO>
cd <NOME_DA_PASTA_DO_PROJETO>
```
### 2. Configurar Vari√°veis de Ambiente

Crie um arquivo chamado `.env` na raiz do projeto, copiando o conte√∫do do arquivo de exemplo `.env.example`.

```bash
# .env

# --- API & RAG Configuration ---
# Cole sua chave de API do Gemini aqui
GEMINI_API_KEY="COLE_SUA_CHAVE_AQUI"
LANGSMITH_PROJECT="desafio-sales-insights" # Opcional: Para tracing com LangSmith

# --- Database Configuration (for Docker Compose) ---
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB=sales_db
POSTGRES_HOST=db
POSTGRES_PORT=5432

# SQLAlchemy Database URL
DATABASE_URL="postgresql://user:password@db:5432/sales_db"
```
### 3. Popular o Banco de Dados com Dados de Exemplo
### 4. Baixe as depend√™ncias: pip install -r requirements.txt
### 5. Inicie o ambiente virtual
### 6. Inicie o servidor fastAPI
### 7. Acesse: ‚û°Ô∏è http://localhost:8000/docs
### 8. No endpoint "/sales-insights" teste a IA
